\BOOKMARK [1][-]{Abstract.1}{Abstract}{}% 1
\BOOKMARK [1][-]{Dedication.1}{Dedication}{}% 2
\BOOKMARK [1][-]{tableofcontents.1}{Contents}{}% 3
\BOOKMARK [1][-]{lof.1}{List of Figures}{}% 4
\BOOKMARK [1][-]{lot.1}{List of Tables}{}% 5
\BOOKMARK [1][-]{acronyms.1}{Acronyms}{}% 6
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 7
\BOOKMARK [0][]{chapter.2}{2 Convolutional neural networks}{}% 8
\BOOKMARK [1][-]{section.2.1}{2.1 Main features}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.2}{2.2 The convolution operation}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.3}{2.3 Architecture}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.3.1}{2.3.1 Convolutional layer}{section.2.3}% 12
\BOOKMARK [2][-]{subsection.2.3.2}{2.3.2 ReLU layer}{section.2.3}% 13
\BOOKMARK [2][-]{subsection.2.3.3}{2.3.3 Pooling layer}{section.2.3}% 14
\BOOKMARK [2][-]{subsection.2.3.4}{2.3.4 Fully connected layer}{section.2.3}% 15
\BOOKMARK [2][-]{subsection.2.3.5}{2.3.5 Dropout layer}{section.2.3}% 16
\BOOKMARK [2][-]{subsection.2.3.6}{2.3.6 Loss layer}{section.2.3}% 17
\BOOKMARK [1][-]{section.2.4}{2.4 Hyperparameters}{chapter.2}% 18
\BOOKMARK [1][-]{section.2.5}{2.5 Applications}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.5.1}{2.5.1 Image recognition}{section.2.5}% 20
\BOOKMARK [2][-]{subsection.2.5.2}{2.5.2 Video analysis}{section.2.5}% 21
\BOOKMARK [2][-]{subsection.2.5.3}{2.5.3 Natural language processing}{section.2.5}% 22
\BOOKMARK [2][-]{subsection.2.5.4}{2.5.4 Drug discovery}{section.2.5}% 23
\BOOKMARK [2][-]{subsection.2.5.5}{2.5.5 Playing Go}{section.2.5}% 24
\BOOKMARK [0][]{chapter.3}{3 Tensorflow basics}{}% 25
\BOOKMARK [1][-]{section.3.1}{3.1 Overview}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.2}{3.2 The computation graph}{chapter.3}% 27
\BOOKMARK [2][-]{subsection.3.2.1}{3.2.1 Building the graph}{section.3.2}% 28
\BOOKMARK [2][-]{subsection.3.2.2}{3.2.2 Launching the graph}{section.3.2}% 29
\BOOKMARK [1][-]{section.3.3}{3.3 Variables}{chapter.3}% 30
\BOOKMARK [2][-]{subsection.3.3.1}{3.3.1 Creation}{section.3.3}% 31
\BOOKMARK [2][-]{subsection.3.3.2}{3.3.2 Initialization}{section.3.3}% 32
\BOOKMARK [2][-]{subsection.3.3.3}{3.3.3 Saving and restoring}{section.3.3}% 33
\BOOKMARK [1][-]{section.3.4}{3.4 Feeds}{chapter.3}% 34
\BOOKMARK [1][-]{section.3.5}{3.5 Tensorboard}{chapter.3}% 35
\BOOKMARK [1][-]{section.3.6}{3.6 A very simple model}{chapter.3}% 36
\BOOKMARK [0][]{chapter.4}{4 A basic model for handwritten digits recognition}{}% 37
\BOOKMARK [1][-]{section.4.1}{4.1 A focus on the MNIST dataset}{chapter.4}% 38
\BOOKMARK [2][-]{subsection.4.1.1}{4.1.1 Usage in the machine learning}{section.4.1}% 39
\BOOKMARK [2][-]{subsection.4.1.2}{4.1.2 Technical informations about images}{section.4.1}% 40
\BOOKMARK [1][-]{section.4.2}{4.2 Choosing the hyperparameters}{chapter.4}% 41
\BOOKMARK [1][-]{section.4.3}{4.3 The architectural level}{chapter.4}% 42
\BOOKMARK [2][-]{subsection.4.3.1}{4.3.1 Weights initialization}{section.4.3}% 43
\BOOKMARK [2][-]{subsection.4.3.2}{4.3.2 First convolutional layer}{section.4.3}% 44
\BOOKMARK [2][-]{subsection.4.3.3}{4.3.3 Second convolutional layer}{section.4.3}% 45
\BOOKMARK [2][-]{subsection.4.3.4}{4.3.4 Digression on the convolution and pooling functions}{section.4.3}% 46
\BOOKMARK [2][-]{subsection.4.3.5}{4.3.5 Densely connected layer}{section.4.3}% 47
\BOOKMARK [2][-]{subsection.4.3.6}{4.3.6 Dropout layer}{section.4.3}% 48
\BOOKMARK [2][-]{subsection.4.3.7}{4.3.7 Loss \(readout\) layer}{section.4.3}% 49
\BOOKMARK [1][-]{section.4.4}{4.4 Training, testing and evaluating the model}{chapter.4}% 50
\BOOKMARK [2][-]{subsection.4.4.1}{4.4.1 Training}{section.4.4}% 51
\BOOKMARK [2][-]{subsection.4.4.2}{4.4.2 Testing and evaluating}{section.4.4}% 52
\BOOKMARK [1][-]{section.4.5}{4.5 Modifications of the architecture}{chapter.4}% 53
\BOOKMARK [1][-]{section.4.6}{4.6 GUI for real time testing}{chapter.4}% 54
\BOOKMARK [1][-]{section.4.7}{4.7 Save and restore a TensorFlow model}{chapter.4}% 55
\BOOKMARK [0][]{chapter.5}{5 Analysis of the collected data}{}% 56
\BOOKMARK [1][-]{section.5.1}{5.1 Gathering data}{chapter.5}% 57
\BOOKMARK [2][-]{subsection.5.1.1}{5.1.1 What, when, why}{section.5.1}% 58
\BOOKMARK [2][-]{subsection.5.1.2}{5.1.2 Storage format}{section.5.1}% 59
\BOOKMARK [1][-]{section.5.2}{5.2 Executions and parameters choice}{chapter.5}% 60
\BOOKMARK [2][-]{subsection.5.2.1}{5.2.1 Number of executions}{section.5.2}% 61
\BOOKMARK [2][-]{subsection.5.2.2}{5.2.2 Number of epochs}{section.5.2}% 62
\BOOKMARK [2][-]{subsection.5.2.3}{5.2.3 Number of filters}{section.5.2}% 63
\BOOKMARK [1][-]{section.5.3}{5.3 Analysis of the training accuracy}{chapter.5}% 64
\BOOKMARK [2][-]{subsection.5.3.1}{5.3.1 Graphics and notations}{section.5.3}% 65
\BOOKMARK [2][-]{subsection.5.3.2}{5.3.2 Training speed}{section.5.3}% 66
\BOOKMARK [2][-]{subsection.5.3.3}{5.3.3 Training stability}{section.5.3}% 67
\BOOKMARK [2][-]{subsection.5.3.4}{5.3.4 Training performance}{section.5.3}% 68
\BOOKMARK [2][-]{subsection.5.3.5}{5.3.5 Training time}{section.5.3}% 69
\BOOKMARK [2][-]{subsection.5.3.6}{5.3.6 Influences of parameters on the network}{section.5.3}% 70
\BOOKMARK [1][-]{section.5.4}{5.4 Analysis of test accuracy}{chapter.5}% 71
\BOOKMARK [1][-]{section.5.5}{5.5 Visualization of filters and feature maps}{chapter.5}% 72
\BOOKMARK [2][-]{subsection.5.5.1}{5.5.1 Input image}{section.5.5}% 73
\BOOKMARK [2][-]{subsection.5.5.2}{5.5.2 Filters of the first convolutional layer}{section.5.5}% 74
\BOOKMARK [2][-]{subsection.5.5.3}{5.5.3 Filters of the second convolutional layer}{section.5.5}% 75
\BOOKMARK [0][]{chapter.6}{6 Conclusions and future work}{}% 76
\BOOKMARK [0][]{dummy.6}{References}{}% 77
